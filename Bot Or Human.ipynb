{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Objectives "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bf4da1ae3d9b421"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Create BERT embeddings for all the sentances in the dataset \n",
    "* Design and train a Bi LSTM to classify the dataset into 0 (generated by humans) and (1s Generated by AI)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11419de0daacb7b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# dataset Description"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93457d922edf2186"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset contains 44,000 paragraphs, some written by humans, some by LLM. the goal of this model is to predict which one is written by LLM and which ones are written by humans "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "868b54642e1d0b1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
    "from transformers import BertModel, BertTokenizer\n",
    "device = torch.device('mps') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:18:15.652992Z",
     "start_time": "2024-11-26T23:18:11.524489Z"
    }
   },
   "id": "89938beedb58331f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "bert model importing "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2747c3325aea541b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  label  \\\n0  Phones\\n\\nModern humans today are always on th...      0   \n1  This essay will explain if drivers should or s...      0   \n2  Driving while the use of cellular devices\\n\\nT...      0   \n3  Phones & Driving\\n\\nDrivers should not be able...      0   \n4  Cell Phone Operation While Driving\\n\\nThe abil...      0   \n\n          prompt_name           source  RDizzl3_seven  \n0  Phones and driving  persuade_corpus          False  \n1  Phones and driving  persuade_corpus          False  \n2  Phones and driving  persuade_corpus          False  \n3  Phones and driving  persuade_corpus          False  \n4  Phones and driving  persuade_corpus          False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>prompt_name</th>\n      <th>source</th>\n      <th>RDizzl3_seven</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones\\n\\nModern humans today are always on th...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices\\n\\nT...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = './dataset/train_v2_drcat_02.csv'\n",
    "data = pd.read_csv(link)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:18:16.325618Z",
     "start_time": "2024-11-26T23:18:15.654604Z"
    }
   },
   "id": "6f2513b773a95157"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "prompt_name\nDoes the electoral college work?         2714\nCar-free cities                          2666\nFacial action coding system              2167\nDistance learning                        2157\nDriverless cars                          1886\nExploring Venus                          1862\nSummer projects                          1750\nMandatory extracurricular activities     1670\nCell phones at school                    1656\nGrades for extracurricular activities    1626\nThe Face on Mars                         1583\nSeeking multiple opinions                1552\nCommunity service                        1542\n\"A Cowboy Who Rode the Waves\"            1372\nPhones and driving                       1168\nName: count, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.label == 0].prompt_name.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:21:35.383855Z",
     "start_time": "2024-11-26T23:21:35.369888Z"
    }
   },
   "id": "fe6e913cafe22d8e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "prompt_name\nSeeking multiple opinions                3624\nDistance learning                        3397\nCar-free cities                          2051\nDoes the electoral college work?         1720\nMandatory extracurricular activities     1407\nSummer projects                           951\nFacial action coding system               917\nCommunity service                         550\n\"A Cowboy Who Rode the Waves\"             524\nGrades for extracurricular activities     490\nCell phones at school                     463\nPhones and driving                        415\nDriverless cars                           364\nExploring Venus                           314\nThe Face on Mars                          310\nName: count, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.label == 1].prompt_name.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:21:37.149479Z",
     "start_time": "2024-11-26T23:21:37.141815Z"
    }
   },
   "id": "8b25c1c457df8edd"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While summer is meant as a break from the regular school routine, having some structured learning over the summer can help students maintain important skills and knowledge. When given the choice, I believe summer projects are best when student-designed rather than teacher-designed.\n",
      "\n",
      "When students have autonomy in choosing their own summer project topics, they are more motivated to engage in meaningful learning. By allowing students to pick subjects they find genuinely interesting or relevant to their lives, they will be internally driven to explore the topic in depth. This type of intrinsic motivation leads to better focus and quality of work compared to assignments chosen by teachers without student input. \n",
      "\n",
      "Giving students ownership over project topics also fosters independence and skill development. By guiding their own work, students learn valuable skills like time management, decision making, and self-directed learning - skills that will serve them well in higher education and careers. Trying to complete a task completely of their own design also builds confidence facing open-ended challenges.\n",
      "\n",
      "Of course, some guidance is still useful to ensure projects have educational merit. Teachers could provide general parameters like the type of final work (essay, presentation, etc.) or subject area but leave the specific focus up to students. This balance of student choice within guidelines maximizes engagement while maintaining academic standards.\n",
      "\n",
      "In conclusion, when the goal is to sustain learning over summer break, student-designed projects are ideal. By letting students follow their interests with some guidance, they are intrinsically driven to dive deeply into self-directed work - an approach that serves their development far better than topics assigned externally. Autonomy, motivation and skill-building will better prepare students for future challenges compared to rigid, teacher-driven assignments over break.\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[25999].text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:19:06.059873Z",
     "start_time": "2024-11-26T23:19:06.057932Z"
    }
   },
   "id": "f8424de9b56644c2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "label\n0    27371\n1    17497\nName: count, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T23:11:33.725652Z",
     "start_time": "2024-11-20T23:11:33.721171Z"
    }
   },
   "id": "672cd769cdaed21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bert model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b839911a5b48cdce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The datasset is passed to textDataset class which processes the dataset and returns it into the form that is most suitable for the model and the bert tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ab298511b24f794"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class textDataset(Dataset): \n",
    "    def __init__(self, dataset, tokenizer, max_length=120):\n",
    "        self.texts = dataset.text.to_list() \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.label = dataset.label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.label[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length = self.max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask':encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T23:11:33.726581Z",
     "start_time": "2024-11-20T23:11:33.724853Z"
    }
   },
   "id": "ea8ca1fce7affabf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "importing the bert model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0f5cee42104a28"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased').to(device=device)\n",
    "model.eval()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T23:11:34.780408Z",
     "start_time": "2024-11-20T23:11:33.727072Z"
    }
   },
   "id": "6d63345fc8cd35b1"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "dataset = textDataset(data, tokenizer=tokenizer, max_length=240)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T23:11:34.783858Z",
     "start_time": "2024-11-20T23:11:34.781703Z"
    }
   },
   "id": "1d8bd9a7a5a07b39"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "del data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T23:11:34.786983Z",
     "start_time": "2024-11-20T23:11:34.783712Z"
    }
   },
   "id": "4a1185efda253a55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating the bert embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af4990b0d7fbd997"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "embeddings_dim = 768 \n",
    "length_of_dataset = len(dataloader.dataset)\n",
    "\n",
    "allEmbeddings = torch.empty(size=(length_of_dataset, embeddings_dim), dtype=torch.float32).to(device=device)\n",
    "allLabels = torch.empty(length_of_dataset, dtype=torch.int64).to(device=device)\n",
    "\n",
    "current_idx = 0\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        if idx % 10 == 0: \n",
    "            print(idx)\n",
    "        input_ids = batch['input_ids'].to(device=device)\n",
    "        attention_mask = batch['attention_mask'].to(device=device)\n",
    "        label = batch['label'].to(device=device)\n",
    "        \n",
    "        # store embeddings\n",
    "        \n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings = output.last_hidden_state[:,0,:]\n",
    "\n",
    "        batch_size = embeddings.size(0)\n",
    "        \n",
    "        allEmbeddings[current_idx: current_idx+ batch_size] = embeddings\n",
    "        allLabels[current_idx:current_idx + batch_size] = label\n",
    "        \n",
    "        current_idx += batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T23:21:37.798308Z",
     "start_time": "2024-11-20T23:11:34.787403Z"
    }
   },
   "id": "90c8737a61063cd7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the embeddings (Run the code from this point on henceforth) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff5e9e8b16927da4"
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[250], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(allEmbeddings, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./Saved Embeddings/embeddings.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'allEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(allEmbeddings, './Saved Embeddings/embeddings.pt')\n",
    "torch.save(allLabels, './Saved Embeddings/outputs.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T22:34:28.248673Z",
     "start_time": "2024-11-26T22:34:28.223486Z"
    }
   },
   "id": "8aa5d133a90048de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here the torch files have been saved. From now on the file will be run from here to save GPU overload "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a820c038056c7bc1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Re run import statements"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "992ed896493b56c1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
    "from torchmetrics import Accuracy\n",
    "device = torch.device('mps')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:08:51.111982Z",
     "start_time": "2024-11-26T23:08:50.555468Z"
    }
   },
   "id": "1b1af910b170fda4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "embeddings = torch.load('./Saved Embeddings/embeddings.pt').to(device=device)\n",
    "labels = torch.load('./Saved Embeddings/outputs.pt').to(device=device).float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:08:51.317352Z",
     "start_time": "2024-11-26T23:08:51.109611Z"
    }
   },
   "id": "e46b7e789fb4b3d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bi directional LSTM  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc0de18429635a15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating the Bi LSTM, with 6 layers and dropout 0.5 \n",
    "The loss function is Cross entropy loss and the activation function is softmax\n",
    "Learning rate is 0.001 and optimizer is Adam \n",
    "These hyperparameters were obtained after hyperparameter tuning "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30e083765bf06743"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class BiDirectionalLSTM(nn.Module):  \n",
    "    def __init__(self, emb_dim=768, hidden_dim=256):\n",
    "        super(BiDirectionalLSTM, self).__init__()\n",
    "        self.LSTM = nn.LSTM(\n",
    "            input_size= emb_dim,\n",
    "            hidden_size= hidden_dim, \n",
    "            num_layers= 6, \n",
    "            dropout= 0.5, \n",
    "            batch_first= True,\n",
    "            bidirectional= True,\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64,2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x): # x is the bert embeddings\n",
    "        x = x.view(-1,1,768)\n",
    "        _, (hidden_state, _) = self.LSTM(x)\n",
    "        lstm_output = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim=1)\n",
    "        output = self.fc(lstm_output)\n",
    "        return output\n",
    "        \n",
    "lstm = BiDirectionalLSTM().to(device=device)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:08:51.367706Z",
     "start_time": "2024-11-26T23:08:51.316207Z"
    }
   },
   "id": "3ecdb31abe2ec3ce"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "lossfn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "opt = Adam(lstm.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:08:52.245584Z",
     "start_time": "2024-11-26T23:08:52.244245Z"
    }
   },
   "id": "5b6a03b8c3e5f7f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the LSTM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "488dedab4407c587"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting the dataset into validation and train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95126ad1b790bd13"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# here need to split into training, validation and testing\n",
    "batch_size = 32\n",
    "dataset = TensorDataset(embeddings, labels)\n",
    "trainDataset, valDataset = random_split(dataset, lengths=[0.7,0.3])\n",
    "trainloader = DataLoader(trainDataset, batch_size=batch_size, shuffle=True)\n",
    "valLoader = DataLoader(valDataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:08:52.473868Z",
     "start_time": "2024-11-26T23:08:52.465887Z"
    }
   },
   "id": "377b6cb7f853d463"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the model for 3 epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e3475c93eca2c91"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time\n",
      "eval time\n",
      "epoch [1/3]\n",
      "        \t training loss: 3.6365216737249284,\n",
      "        \t validation loss: 0.7507696123844653,\n",
      "        \t Training Acc: 0.9575585838003057,\n",
      "        \t Val acc: 0.9821693907875185,\n",
      "            \n",
      "training time\n",
      "eval time\n",
      "epoch [2/3]\n",
      "        \t training loss: 2.1949133417383564,\n",
      "        \t validation loss: 1.843424329998379,\n",
      "        \t Training Acc: 0.9775216505348956,\n",
      "        \t Val acc: 0.9643387815750372,\n",
      "            \n",
      "training time\n",
      "eval time\n",
      "epoch [3/3]\n",
      "        \t training loss: 1.8647686400818202,\n",
      "        \t validation loss: 1.2550570043642437,\n",
      "        \t Training Acc: 0.9805781966377993,\n",
      "        \t Val acc: 0.974739970282318,\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# for softmax cross entropy problem\n",
    "\n",
    "epochs = 3\n",
    "accuracy = Accuracy(task='multiclass', num_classes=2)\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    lstm.train()\n",
    "\n",
    "\n",
    "    if lstm.training:\n",
    "        print('training time')\n",
    "\n",
    "    else:\n",
    "        print('mistake')\n",
    "\n",
    "    correct = 0\n",
    "    for input, targets in trainloader:\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # get outputs for LSTM\n",
    "        output = lstm(input)\n",
    "        \n",
    "        correct += (output.argmax(axis=1) == targets).sum().item()\n",
    "        # get loss value\n",
    "        loss = lossfn(output, targets)\n",
    "        # store loss value\n",
    "        running_loss += loss.item()/len(targets)\n",
    "\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    trainingAcc = correct / len(trainDataset)\n",
    "\n",
    "    # validation\n",
    "    lstm.eval()\n",
    "    if lstm.training:\n",
    "        print('train mode during eval')\n",
    "    else:\n",
    "        print('eval time')\n",
    "    running_val_loss = 0\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in valLoader:\n",
    "        # batchwise output\n",
    "\n",
    "        output = lstm(inputs)\n",
    "        loss = lossfn(output, targets)\n",
    "        running_val_loss += loss.item()/len(targets)\n",
    "\n",
    "        correct += (output.argmax(axis=1) == targets).sum().item()\n",
    "\n",
    "    # validation over \n",
    "    \n",
    "    # printing metrics \n",
    "    val_accuracy = correct / len(valDataset)\n",
    "    print(f'''epoch [{epoch+1}/{epochs}]\n",
    "        \\t training loss: {running_loss},\n",
    "        \\t validation loss: {running_val_loss},\n",
    "        \\t Training Acc: {trainingAcc},\n",
    "        \\t Val acc: {val_accuracy},\n",
    "            ''')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:10:19.988884Z",
     "start_time": "2024-11-26T23:08:54.740398Z"
    }
   },
   "id": "25a2afa10148bdee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving the model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a671e7695f0d2b28"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "torch.save(lstm.state_dict(), './saved model/lstm_model.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:10:52.302146Z",
     "start_time": "2024-11-26T23:10:52.223698Z"
    }
   },
   "id": "3c6eb57f0ebe4a09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load from here for testing the LSTM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59370e0f9a2e7880"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# loading the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b69cdfdd2c8ef55"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "BiDirectionalLSTM(\n  (LSTM): LSTM(768, 256, num_layers=6, batch_first=True, dropout=0.5, bidirectional=True)\n  (fc): Sequential(\n    (0): Linear(in_features=512, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=2, bias=True)\n  )\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = BiDirectionalLSTM().to(device=device)\n",
    "lstm.load_state_dict(torch.load('./saved model/lstm_model.pt', weights_only=True))\n",
    "lstm.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:12:01.210295Z",
     "start_time": "2024-11-26T23:12:01.104871Z"
    }
   },
   "id": "26f65714ff21c024"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
